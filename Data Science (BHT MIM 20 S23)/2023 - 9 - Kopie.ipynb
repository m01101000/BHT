{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies and load data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 2100 [0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0]\n",
      "- - -\n",
      "Validation Accuracy: 0.7261904761904762\n",
      "- - -\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the training data\n",
    "url = \"https://raw.githubusercontent.com/WHPAN0108/BHT-DataScience-S23/main/classification/data/Assigment/aug_train.csv\"\n",
    "train_data = pd.read_csv(url)\n",
    "train_data['experience'] = train_data['experience'].replace(['>20', '<1'], [21, 1])\n",
    "train_data['last_new_job'] = train_data['last_new_job'].replace(['>4', 'never'], [5, 0])\n",
    "categorical_columns = ['gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline', 'company_type']\n",
    "for column in categorical_columns:\n",
    "    train_data[column].fillna(train_data[column].mode()[0], inplace=True)\n",
    "numerical_columns = ['city_development_index', 'training_hours']\n",
    "for column in numerical_columns:\n",
    "    train_data[column].fillna(train_data[column].median(), inplace=True)\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Predict the target variable for the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val_split)\n",
    "\n",
    "a = rf_classifier.predict(X_train)\n",
    "print(\"test:\", len(a), a[0:20])\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "print(\"- - -\")\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "print(\"- - -\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1533   32]\n",
      " [  83  452]]\n",
      "Accuracy: 0.9452380952380952\n",
      "Precision: 0.9338842975206612\n",
      "Recall: 0.8448598130841122\n",
      "F1-score: 0.8871442590775269\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/WHPAN0108/BHT-DataScience-S23/main/classification/data/Assigment/aug_train.csv\"\n",
    "train_data = pd.read_csv(url)\n",
    "\n",
    "# True labels from the test set\n",
    "y_true = train_data['target']\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, a)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_true, a)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y_true, a)\n",
    "\n",
    "# Calculate the recall\n",
    "recall = recall_score(y_true, a)\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1 = f1_score(y_true, a)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted targets: 100 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the test dataset\n",
    "url = \"https://raw.githubusercontent.com/WHPAN0108/BHT-DataScience-S23/main/classification/data/Assigment/aug_test.csv\"\n",
    "test_data = pd.read_csv(url)\n",
    "test_data['experience'] = test_data['experience'].replace(['>20', '<1'], [21, 1])\n",
    "test_data['last_new_job'] = test_data['last_new_job'].replace(['>4', 'never'], [5, 0])\n",
    "categorical_columns = ['gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline', 'company_type']\n",
    "for column in categorical_columns:\n",
    "    test_data[column].fillna(test_data[column].mode()[0], inplace=True)\n",
    "numerical_columns = ['city_development_index', 'training_hours']\n",
    "for column in numerical_columns:\n",
    "    test_data[column].fillna(test_data[column].median(), inplace=True)\n",
    "\n",
    "# Reorder columns to match the training dataset\n",
    "test_data = test_data.reindex(columns=X_val_split.columns, fill_value=0)\n",
    "\n",
    "# Predict the target variable for the new dataset\n",
    "y_pred = rf_classifier.predict(test_data)\n",
    "\n",
    "# Print the predicted values\n",
    "print(\"Predicted targets:\", len(y_pred), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[78  0]\n",
      " [21  1]]\n",
      "Accuracy: 0.79\n",
      "Precision: 1.0\n",
      "Recall: 0.045454545454545456\n",
      "F1-score: 0.08695652173913045\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/WHPAN0108/BHT-DataScience-S23/main/classification/data/Assigment/aug_test.csv\"\n",
    "test_data = pd.read_csv(url)\n",
    "\n",
    "# True labels from the test set\n",
    "y_true = test_data['target']\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "\n",
    "# Calculate the recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the results between the training and test sets, we can examine the performance metrics such as accuracy, precision, recall, and F1-score for both sets. Let's compare the results obtained from the training set and the test set:\n",
    "\n",
    "Training Set:\n",
    "\n",
    "    Confusion Matrix:\n",
    "    [[1533 32]\n",
    "    [ 83 452]]\n",
    "    Accuracy: 0.9452380952380952\n",
    "    Precision: 0.9338842975206612\n",
    "    Recall: 0.8448598130841122\n",
    "    F1-score: 0.8871442590775269\n",
    "\n",
    "Test Set:\n",
    "\n",
    "    Confusion Matrix:\n",
    "    [[78 0]\n",
    "    [21 1]]\n",
    "    Accuracy: 0.79\n",
    "    Precision: 1.0\n",
    "    Recall: 0.045454545454545456\n",
    "    F1-score: 0.08695652173913045\n",
    "\n",
    "Based on the results, we can observe the following differences between the training and test sets:\n",
    "\n",
    "    Accuracy: The accuracy on the training set is 0.9452, while the accuracy on the test set is 0.79. The model performs significantly better on the training set compared to the test set, indicating a potential overfitting issue.\n",
    "\n",
    "    Precision: The precision on the training set is 0.9339, indicating a high percentage of correctly predicted positive cases. However, on the test set, the precision is 1.0, which means all predicted positive cases are correct. This could be due to the small number of positive cases in the test set (only 1), resulting in an inflated precision value.\n",
    "\n",
    "    Recall: The recall on the training set is 0.8449, suggesting that the model can identify a good proportion of positive cases. However, on the test set, the recall is only 0.0455, indicating that the model struggles to identify positive cases in the test set.\n",
    "\n",
    "    F1-score: The F1-score on the training set is 0.8871, which is a harmonic mean of precision and recall. On the test set, the F1-score is 0.0870, indicating a low balance between precision and recall.\n",
    "\n",
    "In summary, the model performs well on the training set with high accuracy, precision, recall, and F1-score. However, when applied to the test set, the performance drops significantly, indicating a potential issue with generalization. It is important to address this overfitting and evaluate the model's performance on unseen data to ensure its reliability and effectiveness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
